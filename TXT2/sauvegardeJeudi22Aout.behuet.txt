Voici la traduction en français :

---

**Méthode de solution**

Notre algorithme de recherche tabou adaptative (ATS) suit un cadre général composé de trois phases : l'initialisation, l'intensification et la diversification. La phase d'initialisation (Section 3.1) construit un emploi du temps initial réalisable en utilisant une heuristique gloutonne rapide. Dès qu'une affectation initiale réalisable est atteinte, la phase combinée d'intensification et de diversification est utilisée pour réduire le nombre de violations des contraintes souples. La phase d'intensification (Section 3.2) utilise un algorithme de recherche tabou [15], tandis que la phase de diversification (Section 3.3.1) est basée sur un opérateur de perturbation guidée par des pénalités, emprunté à la recherche locale itérative [20]. De plus, deux mécanismes auto-adaptatifs (Section 3.3.2) sont employés pour assurer un équilibre entre l'intensification et la diversification.

**3.1. Solution initiale**

La première phase de notre algorithme génère une solution initiale réalisable satisfaisant toutes les contraintes dures (H1 à H4). Cela est réalisé par une heuristique gloutonne séquentielle, en partant d'un emploi du temps vide, dans lequel les affectations de cours sont construites en insérant à chaque étape une séance appropriée dans l'emploi du temps. À chaque étape, deux opérations distinctes sont effectuées : l'une consiste à sélectionner une séance non assignée d'un cours, et l'autre à déterminer une paire période-salle pour cette séance.

Dans l'heuristique de sélection des séances, les cours ayant un petit nombre de périodes disponibles et un grand nombre de séances non assignées sont prioritaires. Cette heuristique est similaire à l'heuristique de coloriage gloutonne DSATUR [4]. Une fois qu'une séance d'un cours a été choisie pour être assignée, nous sélectionnons une période parmi toutes celles disponibles qui est la moins susceptible d'être utilisée par d'autres cours non terminés lors des étapes ultérieures. Pour cela, lorsque nous tentons de réaliser une insertion réalisable, nous comptons le nombre total de cours non terminés qui deviennent indisponibles à la période actuelle. Les mouvements d'insertion de séances réalisables avec une petite valeur de ce nombre sont fortement favorisés. Les égalités sont départagées en fonction de la pénalité des contraintes souples encourue.

Nous n'avons aucune preuve que cette heuristique gloutonne garantit de trouver une solution réalisable pour une instance donnée. Cependant, pour toutes les instances testées dans cet article, une solution réalisable est toujours facilement obtenue. Il est à noter que l'infaisabilité de la solution initiale ne modifie pas l'approche générale de l'ATS, car les contraintes dures non satisfaites peuvent être assouplies et intégrées dans la fonction d'évaluation de l'algorithme ATS.

---

Cette traduction rend fidèlement le contenu technique du texte original en français.

**3.2. Algorithme de Recherche Tabou**

Dans cette section, nous nous concentrons sur le moteur de recherche principal de notre algorithme ATS : la Recherche Tabou [15]. Notre procédure de recherche tabou exploite deux voisinages (notés N1 et N2, voir ci-dessous) de manière séquentielle en anneau [12]. Plus précisément, nous commençons la procédure de recherche tabou avec un voisinage. Lorsque la recherche atteint son meilleur optimum local, nous redémarrons la recherche tabou à partir de cet optimum local, mais avec l'autre voisinage. Ce processus est répété jusqu'à ce qu'aucune amélioration ne soit possible, et nous considérons qu'une phase de recherche tabou est terminée. Dans notre cas, la procédure de recherche tabou commence avec le voisinage de base N1 : N1 → N2 → N1 → N2...

**3.2.1. Espace de recherche et fonction d'évaluation**

Une fois qu'un emploi du temps réalisable qui satisfait toutes les contraintes dures est atteint, notre phase d'intensification (algorithme de recherche tabou) optimise la fonction de coût des contraintes souples sans violer les contraintes dures. Par conséquent, l'espace de recherche de notre algorithme de recherche tabou est limité aux emplois du temps réalisables. La fonction d'évaluation se limite donc aux violations des contraintes souples, telles que définies dans la formule (1).

**3.2.2. Structure du voisinage**

Il est généralement admis que l'une des caractéristiques les plus importantes d'un algorithme de recherche locale est la définition de son voisinage. Dans une procédure de recherche locale, appliquer un mouvement mv à une solution candidate X conduit à une nouvelle solution notée X_mv. Soit M(X) l'ensemble de tous les mouvements possibles qui peuvent être appliqués à X tout en maintenant la faisabilité ; alors, le voisinage N de X est défini par : N(X) = {X_mv | mv ∈ M(X)}. Pour le problème CB-CTT, nous utilisons deux mouvements distincts notés SimpleSwap et KempeSwap.

**Voisinage de base N1 :** N1 est composé de tous les mouvements réalisables de SimpleSwap. Un mouvement SimpleSwap consiste à échanger les périodes et les salles assignées à deux cours différents. Appliquer le mouvement SimpleSwap à deux cours différents xi,j et xi',j' dans la solution X consiste à assigner la valeur de xi,j à xi',j' et inversement, la valeur de xi',j' à xi,j. Il est à noter que déplacer un cours à une position libre est un cas particulier du mouvement SimpleSwap où l'un des cours est vide, et cela est également inclus dans N1. Par conséquent, la taille du voisinage N1 est limitée par O(l * p * m), où l = ∑(n-1) l_i, car il y a l cours et le nombre de cours échangés (y compris les positions libres) est limité par O(p * m).

**Voisinage avancé N2 :** N2 est composé de tous les mouvements réalisables de KempeSwap. Un mouvement KempeSwap est défini par l'échange de deux chaînes de Kempe. Si l'on se concentre uniquement sur les cours et les conflits, chaque instance de problème peut être considérée comme un graphe G où les nœuds représentent les cours et les arêtes relient les cours avec des étudiants ou des enseignants en commun. Dans un emploi du temps réalisable, une chaîne de Kempe est l'ensemble des nœuds qui forment une composante connexe dans le sous-graphe de G induit par les nœuds appartenant à deux périodes. Un KempeSwap produit une nouvelle affectation réalisable en échangeant les étiquettes de période assignées aux cours appartenant à une ou deux chaînes de Kempe spécifiées.

Formellement, soit K1 et K2 deux chaînes de Kempe dans le sous-graphe par rapport à deux périodes ti et tj, un KempeSwap produit une affectation en remplaçant ti par (ti \ (K1 ∪ K2)) ∪ (tj ∩ (K1 ∪ K2)) et tj par (tj \ (K1 ∪ K2)) ∪ (ti ∩ (K1 ∪ K2)). Il est à noter que dans la définition de N2, au moins trois cours sont impliqués, c'est-à-dire que |K1| + |K2| ≥ 3. Par exemple, la figure 1a montre un sous-graphe déduit par deux périodes ti et tj et il y a cinq chaînes de Kempe : Ka = {c1, c2, c7, c8}, Kb = {c3, c6, c9}, Kc = {c4, c11, c12}, Kd = {c5} et Ke = {c10}. Dans cet exemple, chaque salle à ti et tj a un cours. Un KempeSwap de Kb et Kc produit une nouvelle affectation en déplaçant {c3, c4, c6} à tj et {c9, c11, c12} à ti, comme montré dans la figure 1b.

Il est à noter que dans notre KempeSwap, l'une des chaînes de Kempe échangées peut être vide, c'est-à-dire que nous ajoutons une nouvelle chaîne de Kempe vide Kf = ∅. Dans ce cas, le mouvement de KempeSwap dégénère en un simple échange de chaîne de Kempe. Formellement, cela signifie remplacer ti par (ti \ K) ∪ (tj ∩ K) et tj par (tj \ K) ∪ (ti ∩ K) où K est la chaîne de Kempe non vide [22,29]. Par exemple, dans la figure 1a, si nous échangeons les cours de la chaîne de Kempe Ka, cela produit une affectation en déplaçant {c1, c2} à tj et {c7, c8} à ti. Il est à noter que notre double échange de chaînes de Kempe peut être considéré comme une généralisation de l'échange simple de chaîne de Kempe connu dans la littérature [8,29].

Une fois les cours programmés aux périodes, l'affectation des salles peut être effectuée en résolvant un problème d'appariement biparti [24], où des algorithmes heuristiques et exacts peuvent être utilisés. Dans cet article, nous implémentons un algorithme exact, l'algorithme du chemin augmentant implémenté dans [28], qui s'exécute en O(|V||E|).

Puisque KempeSwap peut être considéré comme une version étendue de l'échange de deux cours (et ensuite de plusieurs autres cours liés dans les chaînes de Kempe spécifiées qui sont déplacées), la taille de N2 est limitée par O(l * (l + p)), où la taille de l'échange de double chaîne de Kempe est limitée par O(l²) et la taille de l'échange de simple chaîne de Kempe est limitée par O(l * p).

Afin de maintenir la faisabilité de la solution de voisinage de la chaîne de Kempe, une autre propriété importante doit être vérifiée : le nombre de cours dans chaque période (après l'échange de chaîne de Kempe) ne doit pas dépasser le nombre de salles disponibles. Par exemple, dans la figure 1, en ce qui concerne l'échange de simple chaîne de Kempe, seul un mouvement réalisable peut être produit en échangeant les cours dans Ka, tandis que les quatre autres échanges de simple chaîne de Kempe (Kb, Kc, Kd et Ke) ne peuvent pas produire de solutions réalisables car ces mouvements violent la propriété susmentionnée et sont donc interdits. En fait, cette propriété restreint largement le nombre de solutions candidates acceptables pour les échanges de simple chaîne de Kempe. Nous appelons cette restriction violation de l'allocation des salles.

Cependant, dès que l'échange de double chaîne de Kempe est effectué, la violation de l'allocation des salles est relâchée et un grand nombre de mouvements réalisables peuvent être générés. Par exemple, dans la figure 1, trois échanges de double chaîne de Kempe peuvent être produits en échangeant Kb et Ke, Kc et Kd ainsi que Kb et Kc.

Nous montrerons dans la section 5.2 que le mouvement proposé de double chaîne de Kempe est beaucoup plus puissant que les autres mouvements existants (mouvement d'un seul cours, échange de deux cours et échange de chaîne de Kempe simple) pour la planification des cours [8,18].

**3.2.3. Évaluation incrémentielle et réduction du voisinage**

Afin d'évaluer le voisinage de manière efficace, nous utilisons une technique d'évaluation incrémentielle. L'idée principale est de maintenir dans une structure de données spéciale la valeur de mouvement pour chaque mouvement possible de la solution actuelle. Chaque fois qu'un mouvement est effectué, les éléments de cette structure de données affectés par le mouvement sont mis à jour en conséquence.

Cependant, l'évaluation des mouvements dans le voisinage avancé N2 nécessite beaucoup plus d'efforts de calcul que celle de N1 en raison de l'exécution de l'algorithme d'appariement. Pour économiser du temps CPU, nous essayons d'utiliser l'algorithme d'appariement aussi peu que possible. Selon la formulation du problème, les coûts souples peuvent être classés en coûts liés aux salles (S1 et S2) et coûts liés aux périodes

Voici la traduction en français :

---

**3.2.4. Gestion de la liste tabou**

Dans la recherche tabou (TS), une liste tabou est introduite pour empêcher les solutions précédemment visitées d'être revisitées. Dans notre algorithme TS, lorsqu'une séance est déplacée d'une position (paire période-salle) à une autre (en utilisant N1), ou d'une période à une autre (en utilisant N2), cette séance ne peut pas être déplacée de nouveau vers la position précédente (pour N1) ou la période précédente (pour N2) pendant les tt itérations suivantes (tt est appelé la "durée tabou"). Plus précisément, dans le voisinage N1, si une séance d'un cours ci est déplacée d'une position \((tj, rk)\) à une autre, alors déplacer toute séance du cours ci vers la position \((tj, rk)\) est déclaré tabou. D'autre part, dans le voisinage N2 (soit par un mouvement de chaîne simple ou double de Kempe), si une séance du cours ci est déplacée de la période tj à tk, il est tabou d'assigner une quelconque séance de ci à tj en utilisant un mouvement de chaîne de Kempe (simple ou double).

La durée tabou tt(ci) d'un cours ci est ajustée de manière adaptative en fonction de la qualité actuelle de la solution f et de la fréquence des mouvements impliquant des séances du cours ci, notée tt(ci) = f + u * freq(ci), où u est un paramètre prenant des valeurs entre 0 et 1. La première partie de cette fonction s'explique par le fait qu'une solution avec des pénalités élevées pour les contraintes souples devrait avoir une durée tabou plus longue pour échapper à un optimum local. L'idée derrière la seconde partie est de pénaliser un mouvement qui se répète trop souvent. Le coefficient u est défini dynamiquement comme le ratio du nombre de cours en conflit avec ci sur le nombre total de cours. Il est raisonnable de penser qu'un cours impliqué dans un grand nombre de conflits a plus de risques d'être déplacé qu'un cours ayant moins de conflits. Il est important de noter que freq(ci) est la partie essentielle de la fonction de durée tabou mentionnée ci-dessus, et des techniques de durée tabou basées sur la fréquence ont été utilisées dans la littérature, voir par exemple [30].

**3.2.5. Critères d'aspiration et condition d'arrêt**

Dans notre algorithme TS, le statut tabou d'un mouvement est désactivé s'il conduit à une solution meilleure que la meilleure solution actuelle. Notre TS s'arrête lorsque la meilleure solution ne peut pas être améliorée après un certain nombre h de mouvements, que nous appelons la profondeur de TS.

**3.3. Recherche Tabou Adaptative : Combinaison de TS avec Perturbation**

La recherche tabou (TS) et la recherche locale itérative (ILS) sont deux métaheuristiques bien connues qui ont prouvé leur efficacité pour résoudre séparément un grand nombre de problèmes de satisfaction de contraintes et d'optimisation [15,20]. Dans cet article, nous considérons la possibilité de les combiner pour obtenir des performances très élevées pour le problème CB-CTT.

TS peut être utilisé avec un temps CPU long ou court. En général, un temps CPU long mène à de meilleurs résultats. Cependant, si le temps de calcul total est limité (par exemple, dans le cas de l'ITC-2007), il est préférable de combiner des exécutions courtes de TS avec des opérateurs de diversification robustes. Il est intéressant de noter que l'ILS fournit de tels mécanismes de diversification pour guider la recherche afin d'échapper à l'optimum local actuel et de se diriger vers de nouvelles régions prometteuses de l'espace de recherche [20].

**3.3.1. Une stratégie de perturbation guidée par pénalité**

Dans notre cas, lorsque la meilleure solution ne peut plus être améliorée en utilisant l'algorithme TS, nous employons un opérateur de perturbation pour reconstruire la solution optimale locale obtenue. La force de la perturbation est l'un des facteurs les plus importants de l'ILS. En général, si la perturbation est trop forte, elle peut se comporter comme un redémarrage aléatoire. D'un autre côté, si la perturbation est trop faible, la recherche retomberait dans l'optimum local précédemment visité et l'exploration de l'espace de recherche serait limitée à une petite région.

Pour guider efficacement la recherche vers de nouvelles régions prometteuses de l'espace de recherche, nous employons un opérateur de perturbation guidé par pénalité pour détruire la solution optimale locale atteinte. Cet opérateur se base sur l'identification d'un ensemble des q premières séances les plus pénalisées et sur une sélection aléatoire d'un certain nombre de mouvements de voisinage (dans cet article, nous avons utilisé expérimentalement q = 30). Nous appelons le nombre total de mouvements de perturbation la force de perturbation, notée g.

Plus précisément, lorsque la phase actuelle de TS se termine, toutes les séances sont classées dans un ordre décroissant en fonction des pénalités souples impliquées. Ensuite, g séances sont sélectionnées parmi les q premières séances les plus pénalisées, où la séance de rang k est sélectionnée selon la distribution de probabilité suivante :
\[ \text{P(k)} = \frac{\phi^k}{\sum_{i=1}^{q}\phi^i} \]
où φ est un nombre réel positif (empiriquement fixé à 4,0). Après cela, g mouvements réalisables de SimpleSwap ou KempeSwap sont effectués de manière aléatoire et séquentielle, chacun impliquant au moins l'une des g séances sélectionnées.

Comme mentionné précédemment, la force de perturbation g est l'un des ingrédients les plus importants de l'ILS, car elle détermine l'écart de qualité entre les deux solutions avant et après la perturbation. Dans notre cas, g est ajusté de manière adaptative et prend des valeurs dans un intervalle [gmin, gmax] (fixé expérimentalement à gmin = 4, gmax = 15).

Notre algorithme ATS intègre les phases d'intensification (TS) et de diversification (Perturbation d'ILS). Au lieu de simplement combiner les algorithmes TS et ILS, nous tentons de les intégrer de manière plus significative. La profondeur de TS h et la force de perturbation g semblent être deux paramètres essentiels qui contrôlent le comportement de l'algorithme ATS. D'une part, une valeur de h plus grande assure une recherche plus intensive. D'autre part, une valeur de g plus grande correspond à plus de possibilités d'échapper au minimum local actuel. Pour obtenir un équilibre continu entre intensification et diversification, nous avons mis au point un mécanisme pour ajuster dynamiquement et de manière adaptative ces deux paramètres importants en fonction de l'historique du processus de recherche.

Notre algorithme de recherche tabou adaptative est résumé dans l'algorithme « Adaptive Tabu Search ». Au début de la recherche, nous exécutons une recherche TS courte où la profondeur de TS est faible (disons h = 10). Lorsque TS ne peut plus améliorer sa meilleure solution, une perturbation est appliquée à la meilleure solution avec une faible force (g = gmin). À mesure que la recherche progresse, nous enregistrons le nombre de phases TS (noté n) sans amélioration de la fonction de coût. La profondeur de TS h et la force de perturbation g sont ajustées dynamiquement comme suit : lorsque le minimum local obtenu par TS est prometteur, c'est-à-dire qu'il est proche de la meilleure solution actuelle (f ≤ fbest + 2), h est progressivement augmenté pour assurer une recherche de plus en plus intensive jusqu'à ce qu'aucune amélioration ne soit possible, c'est-à-dire h = (1 + λ) * h à chaque itération (λ = 0,6). De même, la force de perturbation est progressivement augmentée afin de diversifier plus fortement la recherche si le nombre de phases TS sans amélioration augmente. De plus, la recherche revient à une TS courte après chaque perturbation, tandis que la force de perturbation est réinitialisée à gmin dès qu'une meilleure solution est trouvée.

Pour le critère d'acceptation dans le processus de perturbation, nous utilisons une technique d'exploitation forte, c'est-à-dire que seule une meilleure solution est acceptée comme meilleure solution actuelle. Dès que la solution optimale locale X' obtenue par TS est meilleure que la meilleure solution X trouvée jusqu'à présent, nous remplaçons la meilleure solution connue X par X', comme indiqué dans les lignes 18 et 19 de l'algorithme « Adaptive Tabu Search ». Dans cet article, nous utilisons deux conditions d'arrêt comme décrit : la limite de temps imposée par les règles de la compétition ITC-2007 et un nombre maximal de mouvements (voir Section 4).

--- 

Cette traduction reprend fidèlement les concepts complexes et techniques tout en les adaptant pour un public francophone.


AUTRE TRUC 




De nombreux travaux présentent des algorithmes heuristiques pour résoudre le CTT (voir [8], [15], [17], [19]). Comme dans cet article, nous proposons de nouvelles bornes inférieures et des modèles ILP pour le CTT, nous nous concentrons sur la littérature traitant des formulations mathématiques.

Le modèle ILP à trois indices proposé par Burke et al. [5], [6], [7] présente des variables binaires xprc, prenant la valeur 1 si un cours c est donné dans la salle r à la période p. Des variables supplémentaires sont ensuite utilisées pour décrire les contraintes souples dans la fonction objective : des variables entières pour compter le nombre de jours en dessous du nombre minimum de jours ouvrables pour chaque cours, des variables entières pour compter le nombre de cours isolés pour chaque curriculum et chaque jour, et des variables binaires pour exprimer si un cours est donné dans une certaine salle à un moment donné, afin de déterminer le nombre de salles utilisées par chaque cours.

Burke et al. [4] décrivent une méthode, également utilisée dans Burke et al. [5], [7], pour prendre en compte la compacité des curriculums (pénalisation des modèles) : dans les emplois du temps quotidiens, les cours isolés dans la première et la dernière période de la journée sont vérifiés, puis les triples de périodes consécutives avec seulement la période du milieu occupée par un cours sont également vérifiés. Des coupes sont dérivées dans Burke et al. [7] et un algorithme de branch-and-cut est développé. En particulier, les auteurs génèrent un ensemble de coupes nécessaires pour exprimer les contraintes de compacité des curriculums (combinées avec la pénalisation des modèles). Ensuite, des coupes supplémentaires issues de bornes implicites sont introduites : par exemple, chaque cours doit être attribué à au moins une salle et à un nombre de salles n'excédant pas le nombre de cours du programme. Enfin, des coupes générales issues de la coloration de graphes sont introduites, notamment des contraintes basées sur des cliques : étant donné une période et un sous-ensemble de cours correspondant à un sous-graphe complet dans un graphe de conflits, au plus un cours de ces sous-ensembles peut être programmé dans cette période. Dans Burke et al. [5], un modèle ILP appelé Surface est dérivé, qui prend en compte seulement un sous-ensemble des contraintes souples (nombre minimum de jours ouvrables et compacité des curriculums), en négligeant les autres (capacité des salles et stabilité des salles). Il présente des variables binaires wpc prenant la valeur 1 si un cours c est attribué à la période p, en négligeant l’attribution des salles. Dans ce modèle, les auteurs introduisent une contrainte supplémentaire pour chaque période afin d'éviter de programmer plus de cours que le nombre de salles disponibles. Dans le même article, un modèle ILP alternatif, appelé Surface2, est également considéré : alors que dans le modèle Surface toutes les salles sont regroupées en une seule salle de multiplicité égale au nombre de salles disponibles et de capacité égale à la taille de la plus grande salle, dans le modèle Surface2, les salles sont divisées en deux groupes, celles plus grandes et celles plus petites qu'une taille intermédiaire.

Lach et Lübbecke [13] proposent un modèle ILP basé sur la décomposition du problème en deux étapes. La décomposition est exacte par rapport aux contraintes dures et garantit une solution optimale pour l’ensemble du problème si la stabilité des salles n’est pas considérée, comme dans la formulation de base. La première étape vise à attribuer les cours aux périodes. La deuxième étape vise à attribuer des paires (cours, période) aux salles. Le modèle ILP de la première étape est caractérisé par des variables binaires xcp, prenant la valeur 1 si un cours c est donné pendant la période p. À cette étape, toutes les contraintes d'évitement des conflits sont imposées, ainsi que les contraintes prenant en compte la capacité des salles, dérivées par une modification de la condition de Hall (voir [12]), ainsi que les contraintes sur le nombre minimum de jours ouvrables et sur la compacité des curriculums. Des variables supplémentaires sont utilisées dans la première étape pour exprimer les contraintes souples. Lorsque la stabilité des salles est négligée, la deuxième étape consiste à résoudre un ensemble de problèmes de correspondance parfaite pondérée minimum dans un graphe biparti. Si la stabilité des salles est considérée, un modèle ILP est également utilisé dans la deuxième étape.

Hao et Benlic [11] développent une approche basée sur la partition pour dériver des bornes inférieures pour le CTT. Le problème original est divisé en k sous-problèmes, et les contraintes liant les sous-problèmes sont relâchées. En particulier, le relâchement concerne les contraintes souples de compacité des curriculums et les contraintes dures d'occupation des salles et de conflit des périodes (c'est-à-dire que tous les cours appartenant au même curriculum ou enseignés par le même enseignant doivent être programmés dans des périodes distinctes). Chaque sous-problème est ensuite formulé comme un modèle ILP en suivant l'approche proposée par Lach et Lübbecke [13] et résolu par le solveur COIN-OR. La somme des bornes inférieures des sous-problèmes donne une borne inférieure pour le problème original. L'ingrédient principal est la manière de partitionner le problème original : les auteurs proposent une recherche tabou itérée pour dériver une partition efficace.

Asín Achá et Nieuwenhuis [2] appliquent des techniques novatrices basées sur des solveurs de satisfiabilité propositionnelle (SAT) et des optimiseurs. En particulier, les auteurs présentent différentes encodages dans des variantes de SAT (MaxSAT, Partial MaxSAT ou Weighted MaxSAT), dans lesquelles les contraintes souples sont alternativement rendues dures ou souples. De nouvelles meilleures bornes inférieures sont dérivées et de nouvelles meilleures solutions sont obtenues pour certaines instances de référence ITC2007.

Pour conclure, nous souhaitons mentionner que la seule approche basée sur la génération de colonnes dont nous ayons connaissance est celle de Qualizza et Serafini [18], même si une version différente du CTT est étudiée. La principale différence réside dans la fonction objective : des préférences sont accordées aux périodes en raison de considérations pédagogiques et aux enseignants eux-mêmes, et l'objectif est de maximiser ces préférences. Ainsi, ils ne considèrent pas les contraintes souples utilisées dans les formulations de base et étendues. Ils proposent un modèle avec un nombre exponentiel de variables binaires, chacune associée à un emploi du temps hebdomadaire d'un seul cours. Les contraintes dans le problème maître n'autorisent pas l'utilisation de plus que le nombre de salles disponibles pour chaque période, de ne pas programmer plus d'un cours de tout programme appartenant à un curriculum donné dans une période donnée, et d'attribuer un emploi du temps hebdomadaire à chaque cours.
