Bien sûr, voici la traduction en français du texte demandé :

Cet article propose un traitement mathématique du problème de l’emploi du temps basé sur les inscriptions postérieures, un problème NP-difficile, et présente un puissant algorithme métaheuristique en deux étapes pour le résoudre approximativement. Nous nous concentrons particulièrement sur la question de la connectivité de l’espace des solutions et démontrons que lorsque celle-ci est augmentée via des opérateurs de voisinage spécialisés, la qualité des solutions obtenues est généralement améliorée. Sur un ensemble bien connu d’instances de problèmes de référence, notre algorithme proposé produit des résultats supérieurs à toutes les autres méthodes de la littérature; cependant, nous notons également les instances où notre algorithme rencontre des difficultés par rapport à d’autres et offrons des preuves expliquant pourquoi.

1. Introduction
Les emplois du temps sont des structures organisationnelles que l'on trouve dans de nombreux domaines d'activité humaine, y compris le sport (Kendall, Knust, Ribeiro, & Urrutia, 2010), le divertissement (Eliashberg et al., 2009), les transports (Caprara, Fischetti, & Toth, 2002), l'industrie (Blöchliger, 2004) et l'éducation (Lewis, 2008). Dans le contexte des établissements d'enseignement supérieur, un emploi du temps peut être considéré comme une affectation d'événements (tels que des cours, des travaux dirigés ou des examens) à un nombre fini de salles et de créneaux horaires en accord avec un ensemble de contraintes, dont certaines seront obligatoires et d'autres optionnelles (Corne, Ross, & Fang, 1995). Selon McCollum et al. (2010), le problème de construction de tels emplois du temps peut être divisé en deux catégories : les problèmes d'emploi du temps d'examens et les problèmes d'emploi du temps de cours. Il est également suggéré que les problèmes d'emploi du temps de cours peuvent être divisés en deux sous-catégories : « l'emploi du temps de cours basé sur les inscriptions », où les contraintes du problème sont spécifiées par les données d'inscription des étudiants, et « l'emploi du temps de cours basé sur les programmes », où les contraintes sont basées sur les programmes spécifiés par l'université. Müller et Rudova (2012) ont également montré que ces sous-catégories sont étroitement liées, démontrant comment des instances de la seconde peuvent être transformées en celles de la première dans de nombreux cas.

Le domaine de l'emploi du temps universitaire a vu de nombreuses approches de solution proposées au cours des dernières décennies, y compris des méthodes basées sur des heuristiques constructives, la programmation mathématique, le branch and bound, et les métaheuristiques (voir Carter et Laporte, 1996 ; Carter et Laporte, 1998 ; Lewis, 2008 ; Schaerf, 1999 pour des revues de ces méthodes). Une contrainte presque universelle dans les problèmes considérés dans la littérature est la contrainte de « conflit d'événements », qui spécifie que certaines paires d'événements ne peuvent pas être assignées au même créneau horaire (par exemple, il peut y avoir des étudiants qui doivent assister aux deux événements). La présence de cette contrainte permet de faire des parallèles entre la création d'emplois du temps et le bien connu problème NP-difficile de coloration de graphes, et il est certain que des heuristiques dérivées de la coloration de graphes sont souvent utilisées dans les algorithmes de création d'emplois du temps (Burke & Newall, 1999 ; Carter, Laporte, & Lee, 1996 ; Thompson & Dowsland, 1998). Au-delà de cette contrainte cependant, les formulations de problèmes d'emploi du temps ont également tendance à varier considérablement dans la littérature car chaque institution a généralement ses propres besoins et protocoles spécifiques (et donc des contraintes) qui doivent être respectés. Tout en rendant le domaine de recherche très riche, un inconvénient notable a été le manque d'opportunités pour une comparaison précise des algorithmes au fil des ans (Lewis, 2008).

Au cours de la dernière décennie, cette situation a été atténuée dans une certaine mesure grâce à l'organisation d'une série de compétitions de création d'emplois du temps et à la publication d'instances de problèmes disponibles publiquement (http://www.idsia.ch/Files/ttcomp2002 ; http://www.cs.qub.ac.uk/itc2007/ ; http://www.utwente.nl/ctit/hstt/itc2011/welcome/). En 2007, par exemple, la deuxième compétition internationale de création d'emplois du temps (ITC2007) a été organisée par un groupe de chercheurs en emploi du temps de différentes universités européennes, qui a examiné les trois types de problèmes de création d'emplois du temps mentionnés ci-dessus : l'emploi du temps d'examens, l'emploi du temps de cours basé sur les inscriptions et l'emploi du temps de cours basé sur les programmes. La compétition a fonctionné en publiant des instances de problèmes dans le domaine public, les participants concevant ensuite des algorithmes pour essayer de les résoudre. Les algorithmes des participants étaient ensuite comparés sous des délais stricts selon des critères d'évaluation spécifiques. Plus de détails peuvent être trouvés dans McCollum et al. (2010) et sur le site web de la compétition (http://www.cs.qub.ac.uk/itc2007/).

Dans cet article, nous donnons une description mathématique du problème de création d'emplois du temps de cours basé sur les inscriptions utilisé pour ITC2007. Cette formulation particulière modélise la situation réelle où les étudiants ont le choix des cours qu'ils souhaitent suivre, l'emploi du temps étant ensuite construit en fonction de ces choix. Nous présentons un algorithme en deux étapes pour ce problème, en nous concentrant particulièrement sur les questions entourant la connectivité de l'espace des solutions. Nous montrons que lorsque celle-ci est augmentée via des opérateurs de voisinage spécialisés combinés avec des décisions de conception judicieuses, des performances de pointe peuvent être atteintes sur une gamme d'instances de problèmes. Dans la section 3, nous présentons une revue des algorithmes les plus remarquables et/ou récents de haute performance pour ce problème, avant de décrire notre méthode et ses opérateurs dans les sections 4 et 5. Les résultats finaux de notre algorithme sont donnés dans la section 6, avec une discussion et des conclusions présentées dans la section 7.


### Description du problème et prétraitement

Comme mentionné, le problème de l'emploi du temps basé sur les inscriptions postérieures a été introduit pour être utilisé lors de la deuxième compétition internationale de création d'emplois du temps, organisée en 2007 (http://www.cs.qub.ac.uk/itc2007/; Lewis, Paechter, & McCollum, 2007). Le problème implique sept contraintes "dures" (décrites ci-dessous) dont la satisfaction est obligatoire, et trois contraintes "souples", dont la satisfaction est souhaitable, mais non essentielle. Le problème consiste à attribuer un ensemble d'événements à 45 créneaux horaires (5 jours, avec 9 créneaux par jour) selon ces contraintes.

Les contraintes dures pour le problème sont les suivantes. Premièrement, pour chaque événement, il existe un ensemble d'étudiants inscrits pour y assister ; les événements doivent donc être assignés à des créneaux horaires de manière à ce qu'aucun étudiant ne soit tenu d'assister à plus d'un événement à la fois. Ensuite, chaque événement nécessite également un ensemble de caractéristiques de la salle (par exemple, un certain nombre de sièges, des équipements d'enseignement spécialisés, etc.), qui ne seront fournis que par certaines salles ; chaque événement doit donc être attribué à une salle appropriée qui possède les caractéristiques nécessaires. La double réservation des salles est également interdite. Des contraintes dures stipulent également que certains événements ne peuvent pas être enseignés à certains créneaux horaires. Enfin, des contraintes de précédence - indiquant que certains événements doivent être programmés avant ou après d'autres - sont également imposées.

### Contraintes dures
Plus formellement, une instance de problème comprend un ensemble d'événements \( e = \{e_1, \ldots, e_n\} \), un ensemble de créneaux horaires \( t = \{t_1, \ldots, t_{|t|}\} \) (où \( |t| = 45 \)), un ensemble d'étudiants \( s = \{s_1, \ldots, s_m\} \), un ensemble de salles \( r = \{r_1, \ldots, r_{|r|}\} \) et un ensemble de caractéristiques de salles \( f = \{f_1, \ldots, f_{|f|}\} \). Chaque salle \( r_i \in r \) est également attribuée une capacité \( c(r_i) \) reflétant le nombre de sièges qu'elle contient.

Les relations entre ces ensembles sont définies par cinq matrices :

- Une matrice de participation \( P(1) \) de taille \( m \times n \), où \( P(1)_{i,j} = 1 \) si l'étudiant \( s_i \) doit assister à l'événement \( e_j \), et 0 sinon.
- Une matrice des caractéristiques des salles \( P(2) \) de taille \( |r| \times |f| \), où \( P(2)_{i,j} = 1 \) si la salle \( r_i \) possède la caractéristique \( f_j \), et 0 sinon.
- Une matrice des caractéristiques des événements \( P(3) \) de taille \( n \times |f| \), où \( P(3)_{i,j} = 1 \) si l'événement \( e_i \) nécessite la caractéristique \( f_j \), et 0 sinon.
- Une matrice de disponibilité des événements \( P(4) \) de taille \( n \times |t| \), où \( P(4)_{i,j} = 1 \) si l'événement \( e_i \) peut être assigné au créneau \( t_j \), et 0 sinon.
- Une matrice de précédence \( P(5) \) de taille \( n \times n \), où \( P(5)_{i,j} = 1 \) si l'événement \( e_i \) doit être programmé avant l'événement \( e_j \), \( P(5)_{i,j} = -1 \) si l'événement \( e_i \) doit être programmé après l'événement \( e_j \), et 0 sinon.

Pour la matrice de précédence, deux conditions sont nécessaires pour que les relations soient cohérentes : (a) \( P(5)_{i,j} = 1 \iff P(5)_{j,i} = -1 \), et (b) \( P(5)_{i,j} = 0 \iff P(5)_{j,i} = 0 \). Nous pouvons également observer la transitivité de cette relation.

### Matrices supplémentaires
Étant donné les cinq matrices ci-dessus, deux autres matrices sont calculées dans notre approche, permettant une détection rapide des violations des contraintes dures pendant l'exécution de l'algorithme :

- Une matrice de compatibilité des salles \( R \) de taille \( n \times |r| \), où \( R_{i,j} = 1 \) si la salle \( r_j \) est adaptée à l'événement \( e_i \), 0 sinon.
- Une matrice des conflits \( C \) de taille \( n \times n \), où \( C_{i,j} = 1 \) si les événements \( e_i \) et \( e_j \) ne doivent pas être assignés au même créneau, 0 sinon.

### Solution et contraintes
Une solution est représentée par un ensemble ordonné de sous-ensembles \( S = \{S_1, \ldots, S_{|t|}\} \) soumis aux contraintes dures suivantes :

- \( \bigcup_{i=1}^{|t|} S_i \subseteq e \)
- \( S_i \cap S_j = \emptyset \) pour \( 1 \leq i \neq j \leq |t| \)
- Aucun couple d'événements en conflit ne doit être assigné au même sous-ensemble \( S_i \)
- Chaque événement doit être assigné à un sous-ensemble \( S_i \) dont le créneau correspondant \( t_i \) est disponible selon la matrice \( P(4) \)
- Les exigences de précédence doivent être respectées
- Les événements assignés à un sous-ensemble \( S_i \) doivent chacun être assignés à une salle appropriée parmi l'ensemble des salles \( r \)

### Contraintes souples
En plus des contraintes dures, trois contraintes souples sont également considérées :

- SC1 : Les étudiants ne doivent pas être tenus d'assister à un événement dans le dernier créneau de chaque jour (créneaux 9, 18, 27, 36 ou 45).
- SC2 : Les étudiants ne doivent pas avoir à assister à des événements pendant trois créneaux successifs ou plus le même jour.
- SC3 : Les étudiants ne doivent pas être tenus d'assister à un seul événement par jour.

La qualité d'une solution valide est évaluée par une mesure de la distance à la faisabilité (DTF) et le coût des contraintes souples (SCC).

### Complexité du problème
Trouver une solution faisable au problème de l'emploi du temps basé sur les inscriptions postérieures est NP-difficile. Le problème généralise un problème NP-difficile existant, tel que démontré par les contraintes et les relations définies ci-dessus.

### Évaluation
La qualité d'un emploi du temps est décrite par deux valeurs : la distance à la faisabilité (DTF) et le coût des contraintes souples (SCC). Une solution avec le DTF le plus bas est jugée la meilleure, et en cas d'égalité, la solution avec le SCC le plus bas est privilégiée.

Actuellement, il existe 24 instances de problèmes disponibles pour ce problème, toutes connaissant au moins une solution parfaite (DTF = 0 et SCC = 0). Pour des fins de comparaison, un programme de benchmark est également disponible, permettant des comparaisons plus précises des implémentations en utilisant approximativement le même effort computationnel.



### Description de l'algorithme : première étape

Avant de se concentrer sur la tâche d'élimination des violations des contraintes souples, selon l'approche en deux étapes, il est d'abord nécessaire de produire une solution valide qui minimise la mesure DTF (Distance to Feasibility). Les stratégies précédentes pour cette tâche ont généralement consisté à insérer tous les événements dans l'emploi du temps, puis à les réorganiser pour éliminer les violations des contraintes dures. Contrairement à cela, nous choisissons d'utiliser une méthode où les événements peuvent rester en dehors de l'emploi du temps, ce qui signifie que les créneaux ne sont pas "bloqués" par des événements causant des violations de contraintes dures. Pour ce faire, nous utilisons une adaptation de l'algorithme PARTIALCOL, initialement conçu par Blöchliger et Zufferey pour le problème de coloration de graphes.

Pour commencer, une solution initiale est construite en prenant les événements un par un et en les assignant à des créneaux horaires de manière à ce qu'aucune contrainte dure ne soit violée. Les événements qui ne peuvent pas être assignés sans enfreindre une contrainte dure sont mis de côté et traités à la fin de ce processus. Pour essayer de maximiser le nombre d'événements insérés dans l'emploi du temps, nous utilisons un ensemble d'heuristiques de haute performance basées sur l'algorithme de coloration de graphes DSatur. À chaque étape, la règle heuristique h1 est utilisée pour sélectionner un événement, les égalités étant rompues en utilisant h2, puis h3 (si nécessaire).

L'événement sélectionné est ensuite inséré dans l'emploi du temps selon la règle h4, les égalités étant rompues avec h5 et d'autres égalités avec h6.

### Résultats
Le tableau 2 contient les résultats de notre algorithme PARTIALCOL et compare les résultats à ceux rapportés par Cambazard et al. (2012), qui prétendent actuellement obtenir les meilleurs résultats pour ce sous-problème particulier en termes de taux de réussite et de temps d'exécution. Nous rapportons le pourcentage d'exécutions où chaque instance a été résolue (c'est-à-dire où un DTF de zéro a été atteint) et le temps moyen que cela a pris (calculé uniquement à partir des exécutions réussies). Nous voyons que les taux de réussite des deux approches sont similaires, toutes les instances sauf une étant résolues dans 100 % des cas (l'instance n° 10 dans le cas de Cambazard et al., l'instance n° 11 dans le nôtre). Cependant, à l'exception de l'instance n° 11, le temps requis par PARTIALCOL est considérablement moindre, avec une réduction moyenne de 97,4 % du temps CPU sur les 15 autres instances.

Curieusement, en utilisant notre algorithme PARTIALCOL avec l'instance n° 11, la plupart des exécutions ont été résolues très rapidement. Cependant, dans un petit nombre d'exécutions, l'algorithme semblait rapidement atteindre un point où un petit nombre d'événements restaient non placés et où aucune amélioration supplémentaire ne pouvait être apportée, suggérant que la recherche était bloquée dans une vallée évidente du paysage des coûts. Pour remédier à cette situation, nous avons donc ajouté un mécanisme de diversification à la méthode pour tenter de sortir de ces régions. Nous appelons cela notre algorithme PARTIALCOL amélioré et ses résultats sont également donnés dans le tableau 2.

Dans la méthode PARTIALCOL améliorée, notre mécanisme de diversification est utilisé pour apporter des changements relativement importants à la solution en cours, permettant d'explorer de nouvelles régions de l'espace de recherche. Il est appelé lorsque la meilleure solution trouvée jusqu'à présent n'a pas été améliorée pendant un certain nombre d'itérations. Le mécanisme fonctionne en sélectionnant d'abord aléatoirement un pourcentage d'événements dans \( S \) et en les transférant vers l'ensemble des événements non placés \( S_0 \). Ensuite, des modifications sont apportées à \( S \) en effectuant une marche aléatoire en utilisant l'opérateur de voisinage \( N5 \). Enfin, la liste tabu est réinitialisée pour que tous les mouvements potentiels soient considérés comme non-tabu, avant que PARTIALCOL ne continue à s'exécuter comme auparavant. Pour les résultats du tableau 2, le mécanisme de diversification a été appelé après 5000 itérations sans amélioration et a extrait 10 % de tous les événements dans \( S \). Une marche aléatoire de 100 mouvements de voisinage a ensuite été effectuée, donnant une chance de plus de 95 % que tous les créneaux soient modifiés par l'opérateur de voisinage. Nous constatons que la méthode PARTIALCOL améliorée a permis d'atteindre la faisabilité dans toutes les exécutions de l'échantillon, avec la réduction moyenne du temps restant à 97,4 % par rapport à Cambazard et al. (2012).


### Description de l'algorithme : deuxième étape

#### 5.1. Schéma de refroidissement

Dans la deuxième étape de cet algorithme, le recuit simulé (SA) est utilisé pour explorer l'espace des solutions valides/faisables, en essayant de minimiser le nombre de violations des contraintes souples (mesuré par le SCC donné dans l'équation (14)). Cette métaheuristique est appliquée de manière simple : en commençant à une "température" initiale \( T_0 \), pendant l'exécution, la variable de température est lentement réduite selon une règle de mise à jour \( T_{i+1} = \alpha T_i \), où \( \alpha (0 < \alpha < 1) \) est connu comme le "taux de refroidissement". Comme dans nos travaux antérieurs (Lewis, 2012), à chaque température \( T_i \), une chaîne de Markov est générée en effectuant \( n^2 \) applications de l'opérateur de voisinage. Les mouvements qui violent une contrainte dure sont immédiatement rejetés. Les mouvements qui préservent la faisabilité mais augmentent le coût de la solution sont acceptés avec une probabilité \( \exp(-\Delta/T_i) \) (où \( \Delta \) est le changement de coût), tandis que les mouvements qui réduisent ou maintiennent le coût sont toujours acceptés. La température initiale \( T_0 \) est calculée automatiquement en effectuant un petit échantillon de mouvements de voisinage et en utilisant l'écart-type du coût de ces mouvements (van Laarhoven & Aarts, 1987).

Parce que cet algorithme fonctionne selon une limite de temps, notre valeur pour \( \alpha \) est déterminée automatiquement afin que la température soit réduite aussi lentement que possible entre \( T_0 \) et une température finale \( T_{end} \). Dans les recherches existantes (Lewis, 2012 ; Cambazard et al., 2012 ; Kostuch, 2005), cela a été réalisé en effectuant un court pré-run de SA pour évaluer la vitesse à laquelle l'algorithme fonctionne, permettant d'estimer le nombre de chaînes de Markov générées pendant toute l'exécution \( l \). Le taux de refroidissement est alors fixé à \( \alpha = (T_{end}/T_0)^{1/l} \). Cependant, dans notre implémentation, nous avons trouvé cette méthode d'estimation inadéquate car le temps nécessaire pour compléter chaque chaîne de Markov semble également dépendre de la température elle-même, rendant \( l \) difficile à estimer avec précision. Dans notre cas, nous utilisons donc une méthode différente où \( \alpha \) est modifié pendant une exécution selon la durée de chaque chaîne de Markov. Spécifiquement, \( l' \) désigne le nombre estimé de chaînes de Markov qui seront complétées pendant le reste de l'exécution, calculé en divisant le temps d'exécution restant par le temps pris par la chaîne de Markov la plus récente (fonctionnant à la température \( T_i \)). À la fin de la i-ème chaîne de Markov, un taux de refroidissement modifié peut ainsi être calculé comme suit :

\[ \alpha_{i+1} = \left(\frac{T_{end}}{T_i}\right)^{1/l'} \]

Le résultat est que le taux de refroidissement sera légèrement modifié pendant une exécution, permettant d'atteindre la température finale \( T_{end} \) à la limite de temps. Les valeurs appropriées pour \( T_{end} \), le seul paramètre requis pour cette phase, sont examinées dans la section 6.

#### 5.2. Opérateurs de voisinage

Nous définissons maintenant plusieurs opérateurs de voisinage différents qui peuvent être utilisés en conjonction avec l'algorithme SA. Soit \( N(S) \) l'ensemble des solutions candidates dans le voisinage de la solution en cours \( S \). Soit aussi \( S \) l'ensemble de toutes les solutions valides (c'est-à-dire \( S \in S \) si et seulement si les contraintes (4) à (10) sont satisfaites). La relation entre l'espace de solutions et l'opérateur de voisinage peut être définie par un graphe \( G = (S, E) \) avec l'ensemble de sommets \( S \) et l'ensemble d'arêtes \( E = \{(S, S') \in S \times S | S' \in N(S)\} \). Dans notre cas, puisque tous nos opérateurs de voisinage sont réversibles, \( G \) est défini comme un graphe simple, c'est-à-dire \( (S, S') \in E \iff (S', S) \in E \). Les différents opérateurs de voisinage sont maintenant définis.

- **N1** : Le premier opérateur de voisinage est basé sur ceux utilisés par Lewis (2012) et Nothegger et al. (2012). Considérons une solution valide \( S \) représentée comme une matrice \( Z_{|r| \times |t|} \) dans laquelle les lignes représentent des salles et les colonnes représentent des créneaux horaires. Chaque élément de \( Z \) peut être vide ou occupé par exactement un événement. Si \( Z_{i,j} \) est vide, alors la salle \( r_i \) est libre dans le créneau \( t_j \). Si \( Z_{i,j} = e_k \), alors \( e_k \) est assigné à la salle \( r_i \) et au créneau \( t_j \). N1 fonctionne en sélectionnant d'abord aléatoirement un élément \( Z_{i1,j1} \) contenant un événement arbitraire \( e_k \). Un deuxième élément \( Z_{i2,j2} \) est ensuite sélectionné aléatoirement dans un créneau différent (\( j1 \neq j2 \)). Si \( Z_{i2,j2} \) est vide, l'opérateur tente de transférer \( e_k \) du créneau \( j1 \) dans une salle libre du créneau \( j2 \). Si \( Z_{i2,j2} = e_l \), alors un échange est tenté où \( e_k \) est déplacé dans une salle libre du créneau \( j2 \), et \( e_l \) est déplacé dans une salle libre du créneau \( j1 \). Si de tels changements violent des contraintes dures, ils sont immédiatement rejetés, sinon ils sont gardés et la nouvelle solution est évaluée selon l'équation (14).

- **N2** : Cela fonctionne de la même manière que N1. Cependant, lorsqu'il s'agit d'insérer un événement dans un créneau, si aucune salle libre et appropriée n'est disponible, un algorithme de correspondance maximale est également exécuté pour déterminer si une allocation valide des salles peut être trouvée. Un opérateur similaire a été utilisé par Cambazard et al. dans leur entrée gagnante à la compétition (Cambazard et al., 2008).

- **N3** : Ceci est une extension de N2. Spécifiquement, si le mouvement proposé dans N2 entraîne une violation de la contrainte (6), alors un échange de chaîne de Kempe est tenté. Les chaînes de Kempe sont dérivées du modèle de coloration de graphes sous-jacent et correspondent à des sous-graphes connectés contenant des sommets (événements) dans deux classes de couleurs (créneaux horaires). Notez cependant que, comme pour les opérateurs de voisinage précédents, un échange de chaîne de Kempe peut ne pas préserver la satisfaction des autres contraintes dures et devra être rejeté si c'est le cas.

- **N4** : Cet opérateur étend N3 en utilisant l'idée de doubles chaînes de Kempe, initialement proposée par Lü et Hao (2010). Dans de nombreux cas, un échange de chaîne de Kempe proposé sera rejeté car il violera la contrainte (10), c'est-à-dire que des salles appropriées ne peuvent pas être trouvées pour tous les événements proposés pour être assignés à un créneau. Cependant, appliquer une deuxième chaîne de Kempe en même temps peut permettre de maintenir la faisabilité.

- **N5** : Enfin, N5 définit un opérateur d'échange de chaînes de Kempe multiples. Cela généralise N4 en ce sens que si un échange proposé de double chaîne de Kempe est vu pour violer uniquement la contrainte (10), alors des chaînes de Kempe triples, des chaînes de Kempe quadruples (et ainsi de suite) peuvent également être examinées de la même manière.

### 5.3. Salles fictives

Un autre moyen d'améliorer la connectivité de l'espace de solution sous-jacent est l'utilisation de "salles fictives". Une salle fictive est une salle supplémentaire disponible dans tous les créneaux horaires et définie comme appropriée pour tous les événements (c'est-à-dire qu'elle a une capacité de sièges infinie et possède toutes les caractéristiques disponibles des salles). Les salles fictives peuvent être utilisées avec n'importe lequel des opérateurs de voisinage précédents, et plusieurs salles fictives peuvent également être appliquées si nécessaire.

### 5.4. Estimation de la connectivité de l'espace de solution

Nous avons maintenant vu divers opérateurs de voisinage pour ce problème et fait quelques observations sur la connectivité de leurs espaces de recherche sous-jacents, définis par \( G \). Malheureusement, il sera généralement

 très difficile de comprendre complètement la connectivité de \( G \) car il sera simplement trop grand pour être énuméré. En particulier, il est peu probable que nous puissions confirmer si \( G \) est connecté ou non, ce qui serait une information utile si nous voulions savoir si la solution optimale pouvait être atteinte à partir de n'importe quelle autre solution dans l'espace de solution.

Un moyen d'obtenir une indication de la connectivité de \( G \) est d'utiliser ce que nous appellerons le ratio de faisabilité. Cela est défini comme la proportion des mouvements de voisinage proposés qui ne violent aucune des contraintes dures (c'est-à-dire qui maintiennent la validité/la faisabilité). Un ratio de faisabilité plus bas suggère une connectivité plus faible dans \( G \) car, en moyenne, plus de mouvements potentiels violeront une contrainte dure à partir d'une solution particulière, ce qui signifie que les mouvements dans l'espace de solution sont plus restreints. Un ratio de faisabilité plus élevé suggérera une connectivité plus grande.
